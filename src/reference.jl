using SeisIO, JLD2, SeisNoise, Statistics, PlotlyJS
include("utils.jl")
include("io.jl")

"""
    compute_reference_xcorr(finame::String, foname::String, phase_smoothing::Float64=0., stack::String="selective")

Compute cross-correlation function and save data in jld2 file with SeisData format.

# Arguments
- `basefiname::String,`    : Input base file name e.g. "./inputData/BPnetwork"
- `foname::String,`    : Output file name for fully stacked xcorrs e.g. "referenceXcorr.jld2"
- `phase_smoothing::Float64`    : Level of phase_smoothing (0 for linear stacking)
- `stack::String`     : "selective" for selective stacking and "linear" for linear stacking

# Output
- `foname.jld2`    : contains arrays of reference cross-correlations for each station pair

"""
function compute_reference_xcorr(basefiname::String, foname::String; phase_smoothing::Float64=0., stack::String="selective")
    # input file holds metadata (stationlist, timestamplist, etc.)
    f = jldopen(basefiname*".jld2")
    tslist = f["info/timestamplist"]
    close(f) # base xcorr file

    # hold reference xcorrs in memory and write all at once
    ref_dict = Dict()

    # iterate over timestamps
    for (t, tstamp) in enumerate(tslist)
        # read unstacked xcorrs for each time stamp
        f_cur = jldopen(basefiname*".$tstamp.jld2")
        grp = f_cur[tstamp] # xcorrs
        println("stacking xcorrs at $tstamp")

        # iterate over station pairs
        for pair in keys(grp)
            # load xcorr and reverse if necessary
            xcorr = try grp[pair] catch; continue end

            # stack xcorrs over length of CorrData object using either "selective" stacking or "linear" stacking
            if stack=="selective"
                xcorr, rmList = selective_stacking(xcorr)
            else
                stack!(xcorr, allstack=true, phase_smoothing=phase_smoothing)
            end

            # stack xcorrs if they have a key, assign key if not
            if haskey(ref_dict, pair)
                ref_dict[pair].corr .+= xcorr.corr
            else
                ref_dict[pair] = xcorr
            end
        end
        close(f_cur) # current xcorr file
    end

    # write output file of reference xcorrs
    f_ref = jldopen(foname, "a+")
    for pair in keys(ref_dict)
        f_ref[pair] = ref_dict[pair]
    end
    close(f_ref) # reference xcorr file
end

"""
    compute_reference_xcorr(finame::String, existing_reference::String, foname::String; phase_smoothing::Float64=0.)

Compute cross-correlation function and save data in jld2 file with SeisData format.

# Arguments
- `basefiname::String,`    : Input base file name e.g. "./inputData/BPnetwork"
- `existing_reference::String`    : Input file name for precomputed reference to improve e.g. "./refData/referenceXcorr.jld2"
- `foname::String,`    : Output file name for fully stacked xcorrs e.g. "referenceXcorr.jld2"
- `phase_smoothing::Float64=0.`    : Level of phase smoothing for phase weighted stacking. 0. for linear stacking.

# Output
- `foname.jld2`    : contains arrays of reference cross-correlations for each station pair

"""
function compute_reference_xcorr(basefiname::String, existing_reference::String, foname::String; phase_smoothing::Float64=0.)
    # input file holds metadata (stationlist, timestamplist, etc.)
    f = jldopen(basefiname*".jld2")
    tslist = f["info/timestamplist"]
    close(f) # base xcorr file

    # hold reference xcorrs in memory and write all at once
    ref_dict = Dict()

    # existing reference to compare windows to
    f_ref = jldopen(existing_reference)

    # iterate over timestamps
    for (t, tstamp) in enumerate(tslist)
        # read unstacked xcorrs for each time stamp
        f_cur = jldopen(basefiname*".$tstamp.jld2")
        grp = f_cur[tstamp] # xcorrs
        println("stacking xcorrs at $tstamp")

        # iterate over station pairs
        for pair in keys(grp)[1]
            pair = "BP.CCRB..BP1.BP.EADB..BP1"
            # load xcorr
            xcorr = try grp[pair] catch; continue end
            # load reference xcorr
            ref = try f_ref[pair] catch; continue end

            # stack xcorrs over length of CorrData object using selective stacking
            xcorr, nRemoved = selective_stacking(xcorr, ref)

            # stack xcorrs if they have a key, assign key if not
            if haskey(ref_dict, pair)
                ref_dict[pair].corr[:,1] .+= xcorr.corr[:,1]
            else
                ref_dict[pair] = xcorr
            end
        end
        close(f_cur) # current xcorr file
    end

    # write output file of reference xcorrs
    f_ref = jldopen(foname, "a+")
    for pair in keys(ref_dict)
        f_ref[pair] = ref_dict[pair]
    end
    close(f_ref) # reference xcorr file
end

"""
    selective_stacking(data::CorrData; threshold::Float64=0.30, iterations::Int64=3)

Wrapper function for performing selective stacking when given an unstacked CorrData. The reference is generated by linear stacking, and is iteratively improved.

# Arguments
- `data::CorrData,`    : Input CorrData matrix used to define the reference and each window
- `threshold::Float64,`    : Value of correlation-coefficient below which we zero windows
- `iterations::Int64,`    : Number of times to regenerate reference and compute the zeroed windows

# Output
- `stackedData::CorrData,`    : Slectively stacked data
- `removedList::Array{Int64,1},`    : Number of windows removed per iteration

"""
function selective_stacking(data::CorrData; threshold::Float64=0.0, iterations::Int64=3)
    # preliminary stack of all constituent cross-correlations
    stackedData = stack(data, allstack=true)

    # array to hold number of removed windows for each iteration
    removedList = Array{Int64, 1}(undef, iterations)

    # number of iterations to remove incoherent cross-correlations
    for i=1:iterations
        stackedData, removedList[i] = threshold_stacking(data, stackedData, threshold)
    end

    return stackedData, removedList
end

"""
    selective_stacking(data::CorrData, reference::CorrData; threshold::Float64=0.30)

Wrapper function for performing selective stacking when given an unstacked CorrData and a reference CorrData

# Arguments
- `data::CorrData,`    : Input CorrData matrix used to define the reference and each window
- `reference::CorrDat`    : Reference cross-correlation function to use in computing the correlation coefficient
- `threshold::Float64,`    : Value of correlation-coefficient below which we zero windows

# Output
- `stackedData::CorrData,`    : Slectively stacked data
- `removedList::Array{Int64,1},`    : Number of windows removed per iteration
"""
function selective_stacking(data::CorrData, reference::CorrData; threshold::Float64=0.0)
    # number of iterations to remove incoherent cross-correlations
    stackedData, nRemoved = threshold_stacking(data, reference, threshold)

    return stackedData, nRemoved
end

"""
    threshold_stacking(data::CorrData, reference::CorrData, threshold::Float64)

Compute the correlation coefficient between each window and a reference cross-correlation and omit windows with sub-threshold cc's

# Arguments
- `data::CorrData,`    : Input CorrData matrix used to define the reference and each window
- `reference::CorrDat`    : Reference cross-correlation function to use in computing the correlation coefficient
- `threshold::Float64,`    : Value of correlation-coefficient below which we zero windows

# Output
- `stackedData::CorrData,`    : Slectively stacked data
- `removedList::Array{Int64,1},`    : Number of windows removed per iteration
"""
function threshold_stacking(data::CorrData, reference::CorrData, threshold::Float64)
    # array of correlation coefficients for each constituent cross-correlation window
    ccList = Array{Float32,1}(undef,size(data.corr)[2])
    # iterate over each windowed cross-correlation and compute corr-coefficient
    for j=1:size(data.corr)[2]
        ccList[j] = cor(reference.corr[:, 1], data.corr[:, j])
    end

    # find cross-correlations that fall below the cc threshold
    # on the next iteration, do not include these in the reference stack
    good_fit = findall(x->(x>=threshold), ccList)

    # number of sub-threshold cross-correlations
    nRemoved = size(data.corr)[2] - length(good_fit)

    # get SNR for cross-correlations that exceed the correlation coefficient threshold
    tempData = copy(data)
    tempData.corr = tempData.corr[:, good_fit]

    # linearly stack all passable data
    stackedData = stack(tempData, allstack=true)

    return stackedData, nRemoved
end
